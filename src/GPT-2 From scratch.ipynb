{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dutch GPT-2 customized.ipynb","version":"0.3.2","provenance":[{"file_id":"1XgBcNHYVzAco7u8gob1ufkwuw9Ey-BWa","timestamp":1559284688322},{"file_id":"11PD9KRkOYggnz9-rq32buldSCXQKgxgR","timestamp":1557833172045},{"file_id":"1D5t3w5mnCuEkGp3kBxYOHLVCzLqoXYgJ","timestamp":1556095234725}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qjBqj8m6za78","colab_type":"text"},"source":["This colaboratory notebook is used to train OpenAI's GPT-2 model on the Dutch language.\n","\n","Setup:\n","\n","1) Make sure to enable GPU -> Edit > Notebook Settings > Hardware accelarator\n","\n","Note: Colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."]},{"cell_type":"markdown","metadata":{"id":"ib-BLMie0G1N","colab_type":"text"},"source":["## Mount Google Drive\n","Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account"]},{"cell_type":"code","metadata":{"id":"m_1nmGKy0HW_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-bJScukcdak","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDosNBPIz5aK","colab_type":"text"},"source":["Clone repo"]},{"cell_type":"code","metadata":{"id":"WFLQv2e0_Vfh","colab_type":"code","colab":{}},"source":["!git clone https://github.com/zhemann/gpt-2.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxCbG9Bjz8bt","colab_type":"code","colab":{}},"source":["cd gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cFyEzrbZ0AtP","colab_type":"text"},"source":["Install requirements"]},{"cell_type":"code","metadata":{"id":"Z-DgbAqiz-my","colab_type":"code","colab":{}},"source":["!pip3 install -r requirements.txt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xkkgR1kFVDLy","colab_type":"text"},"source":["## Sentencepiece\n","Download, build and install [sentencepiece](https://github.com/google/sentencepiece)\n"]},{"cell_type":"code","metadata":{"id":"lfosO3AGH8YF","colab_type":"code","colab":{}},"source":["!pip3 install sentencepiece"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7gQmmcnYZKm","colab_type":"code","colab":{}},"source":["cd /content"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7iJYbaFkr-Q","colab_type":"code","colab":{}},"source":["%%bash -e\n","if ! [[ -f ./spm_train ]]; then\n","  wget https://github.com/google/sentencepiece/archive/v0.1.82.zip\n","  unzip v0.1.82.zip\n","fi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAabbnBUkx--","colab_type":"code","colab":{}},"source":["% cd sentencepiece-0.1.82\n","% mkdir build\n","% cd build"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOuzTlSDYqkQ","colab_type":"code","colab":{}},"source":["!cmake .."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3k95fM-Yus3","colab_type":"code","colab":{}},"source":["!make -j $(nproc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvZxA5jZYwpb","colab_type":"code","colab":{}},"source":["!sudo make install"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUI4bRc6YywL","colab_type":"code","colab":{}},"source":["!sudo ldconfig -v"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8iDJ5QMvKjda","colab_type":"text"},"source":["## Set Python IO Encoding"]},{"cell_type":"code","metadata":{"id":"mRj2wvH80O76","colab_type":"code","colab":{}},"source":["!export PYTHONIOENCODING=UTF-8"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-GErF9vwqYV","colab_type":"text"},"source":["## Copy dataset\n","To create a new dataset, copy it from your dive directory into colab. "]},{"cell_type":"code","metadata":{"id":"nLUVPAx-WK7I","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDnuMDSOm15y","colab_type":"code","colab":{}},"source":["mkdir data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_6AQC6qWQId","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/data_from_scratch/dataset_wiki.txt /content/gpt-2/data/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4ThdS3gwQLz","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/data_from_scratch/dataset_columns.txt /content/gpt-2/data/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7taZhE0fHE0E","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/data_from_scratch/dataset_books.txt /content/gpt-2/data/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PzFpXWMMnc1t","colab_type":"text"},"source":["## Create dictionary files\n","1. Combine all .txt-files in directory gpt-2/data into one large .txt-file.\n","2. Create dictionary files based on large .txt-file"]},{"cell_type":"code","metadata":{"id":"29zwiwp4VltB","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6Ahi3NVNft3","colab_type":"code","colab":{}},"source":["!sh scripts/concat.sh data datasets_books_columns.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYOOYdNQum2D","colab_type":"code","colab":{}},"source":["!cp datasets_books_columns.txt data/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzb7vya9W87M","colab_type":"code","colab":{}},"source":["!sh scripts/createspmodel.sh data/datasets_combined.txt 40000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"owa5GTwNnye0","colab_type":"code","colab":{}},"source":["mkdir models; cd models; mkdir 117MSP;"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNxfdksexVZB","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJC4SXVuBcCb","colab_type":"code","colab":{}},"source":["!cp hparams_117M.json models/117MSP/hparams.json\n","!cp sp.model models/117MSP/\n","!cp sp.vocab models/117MSP/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nn9OsyyX_IHf","colab_type":"text"},"source":["## Load trained model\n","Load your trained model for use in sampling below. Create directory 'models' if it doesn't exist yet."]},{"cell_type":"code","metadata":{"id":"Qk0uJNN0Ak9y","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2qoJy2x1c82","colab_type":"code","colab":{}},"source":["mkdir models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rdcso2Nz_c_2","colab_type":"text"},"source":["Sometimes the copying messes things up. If this happens, run the following command and re-create models directory (see cell above)"]},{"cell_type":"code","metadata":{"id":"gQ7EcxwdAUy_","colab_type":"code","colab":{}},"source":["rm -r models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"brjK4CRf_nF_","colab_type":"text"},"source":["Load model from drive into 'models' directory"]},{"cell_type":"code","metadata":{"id":"0l8vFo2s-K9k","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/checkpoint_from_scratch/117MSP /content/gpt-2/models/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9RRMcchR4c2","colab_type":"text"},"source":["## Create encoded dataset\n"]},{"cell_type":"code","metadata":{"id":"NoAt98U-WWtY","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/data_from_scratch/dataset_books_columns_enc.npz /content/gpt-2/models/117MSP/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qynfoIa7APWR","colab_type":"text"},"source":["First, run `concat.sh` to create one dataset from multiple files, and to add custom newline tokens `<|n|>` to your dataset. This is necessary as SentencePiece does not add such a token to the dictionairy automatically."]},{"cell_type":"code","metadata":{"id":"SFi9WPYC_z2G","colab_type":"code","colab":{}},"source":["!sh scripts/concat.sh data data/dataset_books_columns_concat.txt "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qSeynQl2A1cB","colab_type":"text"},"source":["Then, run `encode.sh` to encode your dataset"]},{"cell_type":"code","metadata":{"id":"1IWWwpnvZQkp","colab_type":"code","colab":{}},"source":["!sh scripts/encode.sh data/dataset_books_columns_concat.txt 117MSP dataset_books_columns_enc.npz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"onUHnZ2B7HGn","colab_type":"code","colab":{}},"source":["!cp -r /content/gpt-2/models/117MSP/dataset_books_columns_enc.npz /content/drive/My\\ Drive/data_from_scratch/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1tzRSYqU0aJG","colab_type":"text"},"source":["## Train model\n","Start training and save model to drive."]},{"cell_type":"code","metadata":{"id":"38YrSc21_tsW","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OX57AA2k0hR8","colab_type":"code","colab":{}},"source":["!PYTHONPATH=src ./train.py --dataset models/117MSP/dataset_columns_enc.npz --model_name '117MSP' --steps 5000 --sample_every 1000 --save_every 4000 --learning_rate 2.5e-4 --run_name run1 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-pVMW2t0mlX","colab_type":"code","colab":{}},"source":["!cp -r /content/gpt-2/models/117MSP/ /content/drive/My\\ Drive/checkpoint_from_scratch/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LF56302a0kaa","colab_type":"text"},"source":["Train model and save to drive"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"--jdRbOdAxsy","colab":{}},"source":["!PYTHONPATH=src ./train.py --dataset models/117MSP/dataset_columns_enc.npz --model_name '117MSP' --steps 4000 --sample_every 1000 --save_every 30000 --learning_rate 2.5e-4 --run_name run1 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uUM4Q8RlA0t1","colab":{}},"source":["!cp -r /content/gpt-2/models/117MSP/ /content/drive/My\\ Drive/checkpoint_from_scratch/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W4ICXhxRBftM","colab_type":"text"},"source":["Train model and save to drive"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"47mgROYvBF2D","colab":{}},"source":["!PYTHONPATH=src ./train.py --dataset models/117MSP/dataset_columns_enc.npz --model_name '117MSP' --steps 5000 --sample_every 2000 --save_every 30000 --learning_rate 2.5e-4 --run_name run1 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k2em5tz1BF2F","colab":{}},"source":["!cp -r /content/gpt-2/models/117MSP/ /content/drive/My\\ Drive/checkpoint_from_scratch/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-2S093Wm0sNZ","colab_type":"text"},"source":["## Generate samples\n","Generate conditional samples from the model given a prompt you provide - change top-k hyperparameter if desired (default is 40) "]},{"cell_type":"code","metadata":{"id":"ZJt6SwKJx3Jy","colab_type":"code","colab":{}},"source":["!python3 src/interactive_conditional_samples.py --top_k 40 --temperature 0.5 --length 300 --model_name '117MSP' --nsamples 5 --truncate '<|endoftext|>'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xp8ZOBFB0vbU","colab_type":"code","colab":{}},"source":["!python3 src/interactive_conditional_samples.py --top_k 10 --length 300 --model_name '117MSP' --truncate '<|endoftext|>' --include_prefix False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A5ZnPEjo0uQl","colab_type":"text"},"source":["To check flag descriptions, use:"]},{"cell_type":"code","metadata":{"id":"nxrTJZXh0zRo","colab_type":"code","colab":{}},"source":["!python3 src/interactive_conditional_samples.py -- --help"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V8EohQEO00-4","colab_type":"text"},"source":["Generate unconditional samples from the model "]},{"cell_type":"code","metadata":{"id":"dyp8eFEG-ckc","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLNq0plN03GM","colab_type":"code","colab":{}},"source":["!python3 src/generate_unconditional_samples.py --nsamples 25 --length 300 --temperature 0.7 --model_name \"117MSP\" top_k 40 | tee /tmp/samples"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhZQzRLi049y","colab_type":"text"},"source":["To check flag descriptions, use:"]},{"cell_type":"code","metadata":{"id":"M3vmTPzp06ci","colab_type":"code","colab":{}},"source":["!python3 src/generate_unconditional_samples.py -- --help"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fue_Es7ol7-9","colab_type":"text"},"source":["###Unconditional samples manually"]},{"cell_type":"code","metadata":{"id":"XzGWQq8VmRKY","colab_type":"code","colab":{}},"source":["cd /content/gpt-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFrrTfRwl7So","colab_type":"code","colab":{}},"source":["import fire\n","import json\n","import os\n","import numpy as np\n","import tensorflow as tf\n","\n","import model, sample, encoder_sp as encoder\n","\n","def sample_model(\n","    model_name='117M',\n","    seed=None,\n","    nsamples=0,\n","    batch_size=1,\n","    length=None,\n","    temperature=1,\n","    top_k=0,\n","    top_p=0.0,\n","    run_name='run1'\n","):\n","    \"\"\"\n","    Run the sample_model\n","    :model_name=117M : String, which model to use\n","    :seed=None : Integer seed for random number generators, fix seed to\n","     reproduce results\n","    :nsamples=0 : Number of samples to return, if 0, continues to\n","     generate samples indefinately.\n","    :batch_size=1 : Number of batches (only affects speed/memory).\n","    :length=None : Number of tokens in generated text, if None (default), is\n","     determined by model hyperparameters\n","    :temperature=1 : Float value controlling randomness in boltzmann\n","     distribution. Lower temperature results in less random completions. As the\n","     temperature approaches zero, the model will become deterministic and\n","     repetitive. Higher temperature results in more random completions.\n","    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n","     considered for each step (token), resulting in deterministic completions,\n","     while 40 means 40 words are considered at each step. 0 (default) is a\n","     special setting meaning no restrictions. 40 generally is a good value.\n","    :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling,\n","     overriding top_k if set to a value > 0. A good setting is 0.9.\n","    \"\"\"\n","    enc = encoder.get_encoder(model_name)\n","    hparams = model.default_hparams()\n","    with open(os.path.join('models', model_name, 'hparams.json')) as f:\n","        hparams.override_from_dict(json.load(f))\n","\n","    if length is None:\n","        length = hparams.n_ctx\n","    elif length > hparams.n_ctx:\n","        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n","\n","    with tf.Session(graph=tf.Graph()) as sess:\n","        np.random.seed(seed)\n","        tf.set_random_seed(seed)\n","\n","        output = sample.sample_sequence(\n","            hparams=hparams, length=length,\n","            start_token=enc.encode('<|n|>')[0],\n","            batch_size=batch_size,\n","            temperature=temperature, top_k=top_k\n","        )[:, 1:]\n","\n","        saver = tf.train.Saver()\n","        ckpt = tf.train.latest_checkpoint(os.path.join('models', model_name, 'checkpoint/%s' % run_name))\n","        saver.restore(sess, ckpt)\n","\n","        generated = 0\n","        while nsamples == 0 or generated < nsamples:\n","            out = sess.run(output)\n","            for i in range(batch_size):\n","                generated += batch_size\n","                text = enc.decode(out[i])\n","                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n","                \n","if __name__ == '__main__':\n","    fire.Fire(sample_model(\n","      model_name='117MSP',\n","      seed=None,\n","      nsamples=0,\n","      batch_size=1,\n","      length=None,\n","      temperature=1,\n","      top_k=0,\n","      run_name='run1'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7G74kx8lmVXs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}